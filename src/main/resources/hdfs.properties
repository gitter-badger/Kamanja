# zookeeper parameters
zookeeper.connect=127.0.0.1:2181
#zookeeper.session.timeout.ms=400
#zookeeper.sync.time.ms=200
 
# kafka parameters
kafka.group.id= hdfssink
kafka.topic=cops_output

# number of parallel kafka consumers to run
consumer.threads=1

# implementation class to process messages
adapter.message.processor=com.ligadata.adapters.hdfs.BufferedPartitionedAvroSink

# uri to create files under
#hdfs.uri=file:/tmp/data/instrumentationlog
hdfs.uri=hdfs://localhost:9000/bofA/outputAdapter/instrumentationlog
#hdfs.keytabfile.key=
#hdfs.username.key=

# prefix to name all files created under above uri
file.prefix=AppLog

# can be deflate, snappy, bzip2, xz
# if not given, no compression is used
file.compression=bzip2

# SimpleDateFormat format string used to parse date in input message
input.date.format=yyyy-MM-dd

# partition messages using these comma separated ordered list of attributes
# format: attributename1,attributename2,..
# attribute names should match schema definition.
# optional SimpleDateFormat format string can be used after ":" for date attributes 
file.partition.strategy=timestamp:yyyy,timestamp:MM,timestamp:dd

# Avro schema file location
#schema.file=src/main/resources/InstrumentationLog.avsc
schema.file=/opt/Kamanja-1.1.8/services/KafkaOutputAdapter/InstrumentationLog.avsc

# parameters to control message batching
# messages will be written every "count" messages or every "interval" seconds
sync.messages.count=10
sync.interval.seconds=120
